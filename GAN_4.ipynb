{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection u'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /Users/madhvikannan/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /Users/madhvikannan/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /Users/madhvikannan/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /Users/madhvikannan/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /Users/madhvikannan/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /Users/madhvikannan/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /Users/madhvikannan/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /Users/madhvikannan/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /Users/madhvikannan/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /Users/madhvikannan/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /Users/madhvikannan/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     /Users/madhvikannan/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /Users/madhvikannan/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /Users/madhvikannan/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /Users/madhvikannan/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /Users/madhvikannan/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /Users/madhvikannan/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /Users/madhvikannan/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /Users/madhvikannan/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n",
      "Loading model parameters...\n",
      "Compiling encoders...\n",
      "Loading tables...\n",
      "Packing up...\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    " \n",
    "import os\n",
    "import random\n",
    "import sklearn\n",
    "from scipy.ndimage import imread\n",
    "import skipthoughts\n",
    "import nltk\n",
    "\n",
    "\n",
    "# Load cifar-10 data\n",
    "\n",
    "\n",
    "def load_images(path):\n",
    "    working_dir = path\n",
    "    file_list = []\n",
    "    for root, dirs, files in os.walk(working_dir):\n",
    "        for filename in files:\n",
    "            if filename.endswith('.jpg'):\n",
    "                file_list.append(root + \"/\" + filename) \n",
    "    images = []\n",
    "    for myfile in file_list:\n",
    "        image = imread(myfile)\n",
    "        images.append(image)\n",
    "    num_images = len(images)\n",
    "    images=np.asarray(images)\n",
    "    \n",
    "    images=images.reshape(num_images,1,28,28)\n",
    "    images=images.reshape(images.shape[0], 1, 28, 28).transpose(\n",
    "        0, 2, 3, 1).astype(\"uint8\")\n",
    "       \n",
    "    return images / 255.0\n",
    "    \n",
    "def load_input_sentences():\n",
    "    nltk.download('popular')\n",
    "    sentence_file = open('./dataset/input/sentences.txt','r')\n",
    "    sentence = sentence_file.readline()\n",
    "    \n",
    "    sentences = []\n",
    "    solutions = []\n",
    "    \n",
    "    \n",
    "    while sentence != '':\n",
    "        sentences.append(sentence)\n",
    "        solution = sentence.split(' ')[-1]\n",
    "        solutions.append(int(solution))\n",
    "        sentence = sentence_file.readline()\n",
    "    model = skipthoughts.load_model()\n",
    "    encoder = skipthoughts.Encoder(model)\n",
    "\n",
    "    sentences = encoder.encode(sentences)\n",
    "        \n",
    "    return sentences, solutions\n",
    "\n",
    "def load_data(intput_path, output_path):\n",
    "    input_images = load_images(intput_path)\n",
    "    input_sentences, labels = load_input_sentences()\n",
    "    output_images = load_images(output_path)\n",
    "    \n",
    "    inputs = list(zip(input_images, input_sentences, labels, output_images))\n",
    "    random.shuffle(inputs)\n",
    "    input_images, input_sentences, labels,output_images = zip(*inputs)\n",
    "    \n",
    "    return input_images, input_sentences, labels, output_images\n",
    "\n",
    "\n",
    "train_input_path = './dataset/input/'\n",
    "train_output_path = './dataset/output/'\n",
    "train_images, train_sentences, train_labels, train_output= load_data(train_input_path, train_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 28, 28, 2)\n",
      "(?, 28, 28, 3)\n",
      "(?, 28, 28, 3)\n",
      "(?, 28, 28, 64)\n",
      "(?, 28, 28, 1)\n",
      "Iteration 50: dis loss = 6.9375, gen loss = 6.8951\n",
      "Iteration 100: dis loss = 1.1439, gen loss = 1.0709\n",
      "Iteration 150: dis loss = 0.0848, gen loss = 0.0824\n",
      "Iteration 200: dis loss = 0.0495, gen loss = 0.0483\n",
      "Iteration 250: dis loss = 0.0436, gen loss = 0.0427\n",
      "Iteration 300: dis loss = 0.0432, gen loss = 0.0421\n",
      "Iteration 350: dis loss = 0.0398, gen loss = 0.0391\n",
      "Iteration 400: dis loss = 0.0437, gen loss = 0.0426\n",
      "Iteration 450: dis loss = 0.0410, gen loss = 0.0401\n",
      "Iteration 500: dis loss = 0.0456, gen loss = 0.0442\n",
      "Iteration 550: dis loss = 0.0430, gen loss = 0.0420\n",
      "Iteration 600: dis loss = 0.0422, gen loss = 0.0414\n",
      "Iteration 650: dis loss = 0.0393, gen loss = 0.0386\n",
      "Iteration 700: dis loss = 0.0414, gen loss = 0.0408\n",
      "Iteration 750: dis loss = 0.0421, gen loss = 0.0413\n",
      "Iteration 800: dis loss = 0.0391, gen loss = 0.0384\n",
      "Iteration 850: dis loss = 0.0417, gen loss = 0.0408\n",
      "Iteration 900: dis loss = 0.0408, gen loss = 0.0401\n",
      "Iteration 950: dis loss = 0.0397, gen loss = 0.0390\n",
      "Iteration 1000: dis loss = 0.0396, gen loss = 0.0388\n",
      "Iteration 1050: dis loss = 0.0437, gen loss = 0.0431\n",
      "Iteration 1100: dis loss = 0.0402, gen loss = 0.0395\n",
      "Iteration 1150: dis loss = 0.0420, gen loss = 0.0412\n",
      "Iteration 1200: dis loss = 0.0425, gen loss = 0.0417\n",
      "Iteration 1250: dis loss = 0.0430, gen loss = 0.0422\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6a7c9ac457cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0mtrain_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0mdcgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_sentences\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m         \u001b[0mdis_var_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGLOBAL_VARIABLES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mgen_var_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGLOBAL_VARIABLES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gen'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-6a7c9ac457cd>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sess, train_images, train_sentences, train_labels)\u001b[0m\n\u001b[1;32m    268\u001b[0m                 \u001b[0;31m################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdis_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdis_train_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdis_loss_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdis_feed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                 \u001b[0;31m################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/madhvikannan/anaconda/envs/MNIST_Classify/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/madhvikannan/anaconda/envs/MNIST_Classify/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/madhvikannan/anaconda/envs/MNIST_Classify/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/madhvikannan/anaconda/envs/MNIST_Classify/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/madhvikannan/anaconda/envs/MNIST_Classify/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def viz_grid(Xs, padding):\n",
    "    N, H, W, C = Xs.shape\n",
    "    grid_size = int(math.ceil(math.sqrt(N)))\n",
    "    grid_height = H * grid_size + padding * (grid_size + 1)\n",
    "    grid_width = W * grid_size + padding * (grid_size + 1)\n",
    "    grid = np.zeros((grid_height, grid_width, C))\n",
    "    next_idx = 0\n",
    "    y0, y1 = padding, H + padding\n",
    "    for y in range(grid_size):\n",
    "        x0, x1 = padding, W + padding\n",
    "        for x in range(grid_size):\n",
    "            if next_idx < N:\n",
    "                img = Xs[next_idx]\n",
    "                grid[y0:y1, x0:x1] = img\n",
    "                next_idx += 1\n",
    "            x0 += W + padding\n",
    "            x1 += W + padding\n",
    "        y0 += H + padding\n",
    "        y1 += H + padding\n",
    "    return grid\n",
    "\n",
    "def max_pool(input, kernel_size, stride):\n",
    "    ksize = [1, kernel_size, kernel_size, 1]\n",
    "    strides = [1, stride, stride, 1]\n",
    "    return tf.nn.max_pool(input, ksize=ksize, strides=strides, padding='SAME')\n",
    "\n",
    "def conv2d(input, kernel_size, stride, num_filter, name = 'conv2d'):\n",
    "    with tf.variable_scope(name):\n",
    "        stride_shape = [1, stride, stride, 1]\n",
    "        filter_shape = [kernel_size, kernel_size, input.get_shape()[3], num_filter]\n",
    "\n",
    "        W = tf.get_variable('w', filter_shape, tf.float32, tf.random_normal_initializer(0.0, 0.02))\n",
    "        b = tf.get_variable('b', [1, 1, 1, num_filter], initializer = tf.constant_initializer(0.0))\n",
    "        return tf.nn.conv2d(input, W, stride_shape, padding = 'SAME') + b\n",
    "\n",
    "def conv2d_transpose(input, kernel_size, stride, num_filter, name = 'conv2d_transpose'):\n",
    "    with tf.variable_scope(name):\n",
    "        stride_shape = [1, stride, stride, 1]\n",
    "        filter_shape = [kernel_size, kernel_size, num_filter, input.get_shape()[3]]\n",
    "        output_shape = tf.stack([tf.shape(input)[0], tf.shape(input)[1] * 2, tf.shape(input)[2] * 2, num_filter])\n",
    "\n",
    "        W = tf.get_variable('w', filter_shape, tf.float32, tf.random_normal_initializer(0.0, 0.02))\n",
    "        b = tf.get_variable('b', [1, 1, 1, num_filter], initializer = tf.constant_initializer(0.0))\n",
    "        return tf.nn.conv2d_transpose(input, W, output_shape, stride_shape, padding = 'SAME') + b\n",
    "\n",
    "def fc(input, num_output, name = 'fc'):\n",
    "    with tf.variable_scope(name):\n",
    "        num_input = input.get_shape()[1]\n",
    "        W = tf.get_variable('w', [num_input, num_output], tf.float32, tf.random_normal_initializer(0.0, 0.02))\n",
    "        b = tf.get_variable('b', [num_output], initializer = tf.constant_initializer(0.0))\n",
    "        return tf.matmul(input, W) + b\n",
    "\n",
    "def batch_norm(input, is_training):\n",
    "    out = tf.contrib.layers.batch_norm(input, decay = 0.99, center = True, scale = True,\n",
    "                                       is_training = is_training, updates_collections = None)\n",
    "    return out\n",
    "\n",
    "def leaky_relu(input, alpha = 0.2):\n",
    "    return tf.maximum(alpha * input, input)\n",
    "\n",
    "\n",
    "class DCGAN(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.num_epoch = 2\n",
    "        self.batch_size = 32\n",
    "        self.log_step = 50\n",
    "        self.visualize_step = 200\n",
    "        self.code_size = 256\n",
    "        self.learning_rate = 1e-4\n",
    "        self.vis_learning_rate = 1e-2\n",
    "        self.recon_steps = 100\n",
    "        self.actmax_steps = 100\n",
    "        \n",
    "        self._dis_called = False\n",
    "        self._gen_called = False\n",
    "\n",
    "        self.tracked_noise = np.random.normal(0, 1, [64, self.code_size])\n",
    "        self.arr = tf.placeholder(tf.int32, [10,self.batch_size])\n",
    "\n",
    "        self.real_sentences = tf.placeholder(tf.float32, [None, 4800])\n",
    "        self.real_images = tf.placeholder(tf.float32, [None, 28,28,1])\n",
    "        self.real_output_images = tf.placeholder(tf.float32, [None, 28,28,1])\n",
    "        \n",
    "        self.real_labels = tf.placeholder(tf.float32, [None, 100])\n",
    "        self.fake_labels = tf.placeholder(tf.float32, [10, None, 100])\n",
    "        \n",
    "        #self.fake_label = tf.placeholder(tf.float32, [None, 100])\n",
    "        self.noise = tf.placeholder(tf.float32, [None, 256])\n",
    "        \n",
    "        self.is_train = tf.placeholder(tf.bool)\n",
    "        \n",
    "        with tf.variable_scope('actmax'):\n",
    "            self.actmax_code = tf.get_variable('actmax_code', [1, self.code_size],\n",
    "                                               initializer = tf.constant_initializer(0.0))\n",
    "        \n",
    "        self._init_ops()\n",
    "\n",
    "    def _discriminator(self, input):\n",
    "        # We have multiple instances of the discriminator in the same computation graph,\n",
    "        # so set variable sharing if this is not the first invocation of this function.\n",
    "        with tf.variable_scope('dis', reuse = self._dis_called):\n",
    "            self._dis_called = True\n",
    "            \n",
    "            dis_conv1 = conv2d(input, 7, 1, 32, 'conv1')\n",
    "            dis_lrelu1 = leaky_relu(dis_conv1)\n",
    "            dis_maxpool1 = max_pool(dis_lrelu1,3,2 )\n",
    "            \n",
    "            dis_conv2 = conv2d(dis_maxpool1, 5, 1, 64, 'conv2')\n",
    "            dis_batchnorm2 = batch_norm(dis_conv2, self.is_train)\n",
    "            dis_lrelu2 = leaky_relu(dis_batchnorm2)\n",
    "            dis_maxpool2 = max_pool(dis_lrelu2,3,2)     \n",
    "            \n",
    "            dis_conv3 = conv2d(dis_maxpool2, 5, 1, 32, 'conv3')\n",
    "            dis_batchnorm3 = batch_norm(dis_conv3, self.is_train)\n",
    "            dis_lrelu3 = leaky_relu(dis_batchnorm3)\n",
    "            dis_mazpool3 = max_pool(dis_lrelu3,3,2) \n",
    "            \n",
    "            dis_reshape3 = tf.reshape(dis_mazpool3, [-1, 4 * 4 * 32])\n",
    "            dis_fc4 = fc(dis_reshape3, 256, 'fc4')\n",
    "            dis_lrelu3 = leaky_relu(dis_fc4)\n",
    "            dis_fc5 = fc(dis_lrelu3, 100, 'fc5')\n",
    "            \n",
    "            return dis_fc5\n",
    "\n",
    "    def _generator(self, noise,text_embedding, image_input):\n",
    "        with tf.variable_scope('gen', reuse = self._gen_called):\n",
    "            self._gen_called = True\n",
    "            gen_fc1 = fc(text_embedding, 256, 'fc1')\n",
    "            gen_relu1 = leaky_relu(gen_fc1)\n",
    "            z_text = tf.concat([noise, gen_relu1], 1)\n",
    "            \n",
    "            gen_fc2 = fc(z_text, 784*2, 'fc2')\n",
    "            gen_relu2 = leaky_relu(gen_fc2)\n",
    "            \n",
    "            gen_reshape1 = tf.reshape(gen_relu2, [-1, 28, 28, 2])\n",
    "            print gen_reshape1.shape\n",
    "            image_reshape = tf.concat([image_input, gen_reshape1],3)\n",
    "            print image_reshape.shape\n",
    "            \n",
    "            gen_batchnorm1 = batch_norm(image_reshape, self.is_train)\n",
    "            gen_lrelu1 = leaky_relu(gen_batchnorm1)\n",
    "            print gen_lrelu1.shape\n",
    "            gen_conv2 = conv2d(gen_lrelu1, 4, 1, 64, 'conv2')\n",
    "            gen_batchnorm2 = batch_norm(gen_conv2, self.is_train)\n",
    "            gen_lrelu2 = leaky_relu(gen_batchnorm2)\n",
    "            print(gen_lrelu2.shape)\n",
    "            gen_conv3 = conv2d(gen_lrelu2, 4, 1, 32, 'conv3')\n",
    "            gen_batchnorm3 = batch_norm(gen_conv3, self.is_train)\n",
    "            gen_lrelu3 = leaky_relu(gen_batchnorm3)\n",
    "            gen_conv4 = conv2d(gen_lrelu3, 4, 1, 1, 'conv4')\n",
    "            \n",
    "            gen_sigmoid4 = tf.sigmoid(gen_conv4)\n",
    "            print(gen_sigmoid4.shape)\n",
    "            return gen_sigmoid4\n",
    "\n",
    "    def _loss(self, labels, logits):\n",
    "        loss = tf.nn.sigmoid_cross_entropy_with_logits(labels = labels, logits = logits)\n",
    "        return tf.reduce_mean(loss)\n",
    "\n",
    "    def _reconstruction_loss(self, generated, target):\n",
    "        loss = tf.nn.l2_loss(generated - target)\n",
    "        return tf.reduce_mean(loss)\n",
    "    \n",
    "    # Define operations\n",
    "    def _init_ops(self):\n",
    "        \n",
    "        ################################################################################\n",
    "        # Prob 2-1: complete the definition of these operations                        #\n",
    "        ################################################################################\n",
    "        \n",
    "        self.fake_samples_op = self._generator(self.noise, self.real_sentences,self.real_images)\n",
    "        self.dis_loss_op = self._loss(self.real_labels,self._discriminator(self.real_output_images))\n",
    "        \n",
    "        fake_label_list = []\n",
    "        \n",
    "        for i in range(10):\n",
    "            #print(self.fake_labels[i].shape, tf.one_hot(self.arr[i],100).shape )\n",
    "            fake_label_list.append(tf.one_hot(self.arr[i],100))\n",
    "        \n",
    "        fake_labels = tf.stack(fake_label_list)\n",
    "        \n",
    "        for i in range(self.fake_labels.shape[0]):\n",
    "            self.dis_loss_op = self.dis_loss_op + self._loss(self.fake_labels[i], self._discriminator(self.fake_samples_op))\n",
    "        self.gen_loss_op = self.dis_loss_op\n",
    "            #self.gen_loss_op= self.dis_loss_op + self._loss(self.fake_labels[i], self._discriminator(self.fake_samples_op))       \n",
    "        \n",
    "        \n",
    "        \n",
    "        ################################################################################\n",
    "        # Prob 2-1: fix the definition of these operations                             #\n",
    "        ################################################################################\n",
    "        \n",
    "        dis_optimizer = tf.train.RMSPropOptimizer(self.learning_rate)\n",
    "        first_train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                                     \"dis\")\n",
    "        self.dis_train_op = dis_optimizer.minimize(self.dis_loss_op,var_list = first_train_vars)\n",
    "        \n",
    "        gen_optimizer = tf.train.RMSPropOptimizer(self.learning_rate)\n",
    "        second_train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                                     \"gen\")\n",
    "        self.gen_train_op = gen_optimizer.minimize(self.gen_loss_op, var_list = second_train_vars)\n",
    "\n",
    "    # Training function\n",
    "    def train(self, sess,train_images,train_sentences,train_labels ):\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        num_train = train_images.shape[0]\n",
    "        step = 0\n",
    "        \n",
    "        # smooth the loss curve so that it does not fluctuate too much\n",
    "        smooth_factor = 0.95\n",
    "        plot_dis_s = 0\n",
    "        plot_gen_s = 0\n",
    "        plot_ws = 0\n",
    "        \n",
    "        dis_losses = []\n",
    "        gen_losses = []\n",
    "        for epoch in range(self.num_epoch):\n",
    "            for i in range(num_train // (self.batch_size)):\n",
    "                step += 1\n",
    "\n",
    "                image_batch = train_images[i * self.batch_size : (i + 1) * self.batch_size]\n",
    "                output_batch = train_output[i * self.batch_size : (i + 1) * self.batch_size]\n",
    "                sentence_batch = train_sentences[i * self.batch_size : (i + 1) * self.batch_size]\n",
    "                noise = np.random.normal(0, 1, [self.batch_size, 256])\n",
    "                real_labels = np.zeros([32,100])\n",
    "                \n",
    "                for j in range(32):\n",
    "                    real_labels[j][train_labels[i * self.batch_size + j]] = 1\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                arr = np.zeros([10,self.batch_size],dtype=np.int32)\n",
    "                for i in range(self.batch_size):\n",
    "                    for j in range(10):\n",
    "                        num = random.randint(0,100)\n",
    "                        if num != train_labels[i]:\n",
    "                            arr[j][i] = num\n",
    "                            \n",
    "                #fake_labels = np.zeros([10,self.batch_size,100])\n",
    "                #for i in range(10):\n",
    "                    #print(fake_labels[i].shape, tf.one_hot(arr[i],100).shape )\n",
    "                    #fake_labels[i] = tf.one_hot(arr[i],100)\n",
    "                    \n",
    "                \n",
    "                #labels = np.zeros([self.batch_size,100])\n",
    "                #fake_labels = np.zeros([self.batch_size,10,100])\n",
    "                \n",
    "                #for j in range(self.batch_size ):\n",
    "                    #index = 0\n",
    "                    #for k in range(10):\n",
    "                        #index = random.randint(0,99)\n",
    "                        #if index != train_labels[i*self.batch_size + j]:\n",
    "                            #fake_labels[j][k][index] = 1\n",
    "                        #else:\n",
    "                            #k = k - 1\n",
    "\n",
    "                ################################################################################\n",
    "                # Prob 2-1: complete the feed dictionary                                       #\n",
    "                ################################################################################\n",
    "                \n",
    "                dis_feed_dict = {self.real_images:image_batch, self.real_output_images:output_batch, self.real_sentences:sentence_batch ,self.real_labels:real_labels, self.fake_labels:np.zeros([10,32,100]), self.noise:noise, self.arr:arr, self.is_train:True}\n",
    "        \n",
    "                ################################################################################\n",
    "                #                               END OF YOUR CODE                               #\n",
    "                ################################################################################\n",
    "\n",
    "                _, dis_loss = sess.run([self.dis_train_op, self.dis_loss_op], feed_dict = dis_feed_dict)\n",
    "        \n",
    "                ################################################################################\n",
    "                # Prob 2-1: complete the feed dictionary                                       #\n",
    "                ################################################################################\n",
    "                \n",
    "                gen_feed_dict = {self.real_images:image_batch, self.real_output_images:output_batch, self.real_sentences:sentence_batch ,self.real_labels:real_labels, self.fake_labels:np.zeros([10,32,100]), self.noise:noise, self.arr:arr, self.is_train:True}\n",
    "        \n",
    "                ################################################################################\n",
    "                #                               END OF YOUR CODE                               #\n",
    "                ################################################################################\n",
    "\n",
    "                _, gen_loss = sess.run([self.gen_train_op, self.gen_loss_op], feed_dict = gen_feed_dict)\n",
    "\n",
    "                plot_dis_s = plot_dis_s * smooth_factor + dis_loss * (1 - smooth_factor)\n",
    "                plot_gen_s = plot_gen_s * smooth_factor + gen_loss * (1 - smooth_factor)\n",
    "                plot_ws = plot_ws * smooth_factor + (1 - smooth_factor)\n",
    "                dis_losses.append(plot_dis_s / plot_ws)\n",
    "                gen_losses.append(plot_gen_s / plot_ws)\n",
    "\n",
    "                if step % self.log_step == 0:\n",
    "                    print('Iteration {0}: dis loss = {1:.4f}, gen loss = {2:.4f}'.format(step, dis_loss, gen_loss))\n",
    "\n",
    "            #fig = plt.figure(figsize = (8, 8))   \n",
    "            #ax1 = plt.subplot(111)\n",
    "            #generated_image = self.generate(self.tracked_noise)\n",
    "            #print(generated_image.shape)\n",
    "            #image = viz_grid(generated_image, 1)\n",
    "            #print(image.shape)\n",
    "            #image = image.reshape(30,30)\n",
    "            #list = []\n",
    "            #for i in range(3):\n",
    "                #for j in range(image.shape[0]):\n",
    "                    #list.append(image[j])\n",
    "            #image = np.array(list)\n",
    "            #image = image.reshape(30,30,3)\n",
    "            \n",
    "            fig = plt.figure(figsize = (8, 8))   \n",
    "            ax1 = plt.subplot(111)\n",
    "            gen = self.generate(self.tracked_noise)\n",
    "            print (gen.shape)\n",
    "            images = viz_grid(gen, 1)\n",
    "            images = images.reshape(233,233)\n",
    "            ax1.imshow(images,cmap='gray')\n",
    "            plt.show()\n",
    "\n",
    "            plt.plot(dis_losses)\n",
    "            plt.title('discriminator loss')\n",
    "            plt.xlabel('iterations')\n",
    "            plt.ylabel('loss')\n",
    "            plt.show()\n",
    "\n",
    "            plt.plot(gen_losses)\n",
    "            plt.title('generator loss')\n",
    "            plt.xlabel('iterations')\n",
    "            plt.ylabel('loss')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "    # Generates a single sample from input code\n",
    "    def generate_one_sample(self, code, i):\n",
    "        \n",
    "        ################################################################################\n",
    "        # Prob 2-1: complete the feed dictionary                                       #\n",
    "        ################################################################################\n",
    "        image_batch = train_images[ i : i+1]\n",
    "        sentence_batch = train_sentences[i : i+1]\n",
    "        gen_vis_feed_dict = {self.noise:code,self.real_images:image_batch, self.real_sentences:sentence_batch, self.is_train:True}\n",
    "        \n",
    "        ################################################################################\n",
    "        #                               END OF YOUR CODE                               #\n",
    "        ################################################################################\n",
    "        \n",
    "        generated = sess.run(self.fake_samples_op, feed_dict = gen_vis_feed_dict)\n",
    "        return generated\n",
    "\n",
    "    # Generates samples from input batch of codes\n",
    "    def generate(self, codes):\n",
    "        generated = np.zeros((codes.shape[0], 28, 28, 1))\n",
    "        for i in range(codes.shape[0]):\n",
    "            generated[i:i+1] = self.generate_one_sample(codes[i:i+1],i)\n",
    "        return generated\n",
    "\n",
    "\n",
    "\n",
    "    # Perform activation maximization on a batch of different initial codes\n",
    "    def actmax(self, initial_codes):\n",
    "        actmax_results = np.zeros((initial_codes.shape[0], 32, 32, 3))\n",
    "        for i in range(initial_codes.shape[0]):\n",
    "            actmax_results[i:i+1] = self.actmax_one_sample(initial_codes[i:i+1])\n",
    "        return actmax_results.clip(0, 1)\n",
    "    \n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    with tf.device('/cpu:0'):\n",
    "        dcgan = DCGAN()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        train_images = np.array(train_images)\n",
    "        train_sentences = np.array(train_sentences)\n",
    "        train_labels = np.array(train_labels)\n",
    "        train_images = np.array(train_images)\n",
    "        dcgan.train(sess, train_images,train_sentences,train_labels)\n",
    "        dis_var_list = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, 'dis')\n",
    "        gen_var_list = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, 'gen')\n",
    "        saver = tf.train.Saver(dis_var_list + gen_var_list)\n",
    "        saver.save(sess, 'model/dcgan')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
